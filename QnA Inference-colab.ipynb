{"cells":[{"cell_type":"markdown","source":["# **HitlerGPT - QnA inference**\n","https://github.com/FENRlR/HitlerGPT"],"metadata":{"id":"6OEraE5nWopm"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"D9bR72TPp51z"},"outputs":[],"source":["!pip install -q -U bitsandbytes\n","!pip install -q -U git+https://github.com/huggingface/transformers.git\n","!pip install -q -U git+https://github.com/huggingface/peft.git\n","!pip install -q -U git+https://github.com/huggingface/accelerate.git\n","!pip install -q datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J8bnGEzMp1E4"},"outputs":[],"source":["!git clone https://github.com/FENRlR/HitlerGPT\n","%cd /content/HitlerGPT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2GdP5F9Ap-gF"},"outputs":[],"source":["import torch\n","from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n","\n","model_id = \"EleutherAI/pythia-410m-deduped\"\n","\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.bfloat16\n",")\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_id)\n","tokenizer.pad_token = tokenizer.eos_token # needed for gpt-neo-x tokenizer\n","model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map={\"\":0})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4ZRujE8aqLX2"},"outputs":[],"source":["outfolder = \"combination\"\n","resumep = f\"./{outfolder}\"\n","checkpoint = \"138622\" # 151218, 138622, 126020, 100816, 75612\n","resumep = f\"./{outfolder}/checkpoint-{checkpoint}\"\n","from peft import PeftModel\n","model = PeftModel.from_pretrained(model, resumep)"]},{"cell_type":"code","source":["def gen4(x):\n","    gened = model.generate(\n","        **tokenizer(\n","            f\"###QST: {x}\\n\\n###ANS:\",\n","            return_tensors='pt',\n","            return_token_type_ids=False\n","        ).to(0),\n","        #max_new_tokens=512,\n","        max_new_tokens=256,\n","        early_stopping=True,\n","        do_sample=True,\n","        eos_token_id=2,\n","        repetition_penalty=1.2,#1.3,\n","    )\n","    return tokenizer.decode(gened[0]).replace('#','')"],"metadata":{"id":"OjPc1gCos9bR"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5SgXfvSFRj7y"},"outputs":[],"source":["while 1:\n","  q = input('user > ').strip()\n","  if q == 'quit':\n","    break\n","  print(gen4(q))"]}],"metadata":{"accelerator":"GPU","colab":{"toc_visible":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}